{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a37b501",
   "metadata": {},
   "source": [
    "# Improved Disease Detection Model Training\n",
    "\n",
    "This notebook provides an enhanced approach to training the animal skin disease detection model with:\n",
    "- EfficientNetB0 architecture (better than InceptionV3)\n",
    "- Improved data augmentation\n",
    "- Better evaluation metrics\n",
    "- Proper callbacks and training strategies\n",
    "- Cross-validation support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc180cb",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5d4a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger\n",
    ")\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a7b7ea",
   "metadata": {},
   "source": [
    "## 2. Configuration and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a609c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    'IMG_SIZE': 224,  # EfficientNet works better with 224x224\n",
    "    'BATCH_SIZE': 16,  # Larger batch size for better training\n",
    "    'EPOCHS': 100,\n",
    "    'LEARNING_RATE': 0.001,\n",
    "    'NUM_CLASSES': 3,\n",
    "    'CLASS_NAMES': ['Bacterial', 'Fungal', 'Healthy'],\n",
    "    'TRAIN_DIR': './src/Train',\n",
    "    'VAL_DIR': './src/Validation',\n",
    "    'TEST_DIR': './src/Test',\n",
    "    'MODEL_DIR': './model',\n",
    "    'LOGS_DIR': './logs'\n",
    "}\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(CONFIG['MODEL_DIR'], exist_ok=True)\n",
    "os.makedirs(CONFIG['LOGS_DIR'], exist_ok=True)\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383f22a6",
   "metadata": {},
   "source": [
    "## 3. Enhanced Data Generators with Better Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f918fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generators():\n",
    "    \"\"\"Create enhanced data generators with better augmentation\"\"\"\n",
    "    \n",
    "    # Training data generator with extensive augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=45,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        shear_range=0.3,\n",
    "        zoom_range=0.3,\n",
    "        brightness_range=[0.7, 1.3],\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=0.2  # Use 20% for validation if no separate val folder\n",
    "    )\n",
    "    \n",
    "    # Validation and test data generators (no augmentation)\n",
    "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # Training generator\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        CONFIG['TRAIN_DIR'],\n",
    "        target_size=(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']),\n",
    "        batch_size=CONFIG['BATCH_SIZE'],\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Validation generator\n",
    "    if os.path.exists(CONFIG['VAL_DIR']):\n",
    "        val_generator = val_test_datagen.flow_from_directory(\n",
    "            CONFIG['VAL_DIR'],\n",
    "            target_size=(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']),\n",
    "            batch_size=CONFIG['BATCH_SIZE'],\n",
    "            class_mode='categorical',\n",
    "            shuffle=False\n",
    "        )\n",
    "    else:\n",
    "        print(\"No separate validation directory found. Using training split.\")\n",
    "        val_generator = None\n",
    "    \n",
    "    # Test generator (if exists)\n",
    "    test_generator = None\n",
    "    if os.path.exists(CONFIG['TEST_DIR']):\n",
    "        test_generator = val_test_datagen.flow_from_directory(\n",
    "            CONFIG['TEST_DIR'],\n",
    "            target_size=(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE']),\n",
    "            batch_size=CONFIG['BATCH_SIZE'],\n",
    "            class_mode='categorical',\n",
    "            shuffle=False\n",
    "        )\n",
    "    \n",
    "    return train_generator, val_generator, test_generator\n",
    "\n",
    "# Create generators\n",
    "train_gen, val_gen, test_gen = create_data_generators()\n",
    "\n",
    "print(f\"Training samples: {train_gen.samples}\")\n",
    "if val_gen:\n",
    "    print(f\"Validation samples: {val_gen.samples}\")\n",
    "if test_gen:\n",
    "    print(f\"Test samples: {test_gen.samples}\")\n",
    "print(f\"Class indices: {train_gen.class_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9979effd",
   "metadata": {},
   "source": [
    "## 4. Build Enhanced Model with EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2381e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_efficientnet_model():\n",
    "    \"\"\"Create an improved model using EfficientNetB0\"\"\"\n",
    "    \n",
    "    # Load pre-trained EfficientNetB0 (better than InceptionV3)\n",
    "    base_model = EfficientNetB0(\n",
    "        input_shape=(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE'], 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    \n",
    "    # Freeze base model initially\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add custom classification head\n",
    "    inputs = tf.keras.Input(shape=(CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE'], 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(CONFIG['NUM_CLASSES'], activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Create the model\n",
    "model, base_model = create_efficientnet_model()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=CONFIG['LEARNING_RATE']),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n",
    "# Save model architecture plot\n",
    "plot_model(model, to_file=f\"{CONFIG['MODEL_DIR']}/model_architecture.png\", \n",
    "           show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c938ba2b",
   "metadata": {},
   "source": [
    "## 5. Setup Advanced Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea7c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks():\n",
    "    \"\"\"Create advanced callbacks for better training\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    callbacks = [\n",
    "        # Early stopping to prevent overfitting\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Reduce learning rate when validation loss plateaus\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=7,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Save best model\n",
    "        ModelCheckpoint(\n",
    "            filepath=f\"{CONFIG['MODEL_DIR']}/best_model_{timestamp}.h5\",\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Log training metrics\n",
    "        CSVLogger(\n",
    "            filename=f\"{CONFIG['LOGS_DIR']}/training_log_{timestamp}.csv\",\n",
    "            append=True\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return callbacks\n",
    "\n",
    "callbacks = create_callbacks()\n",
    "print(f\"Created {len(callbacks)} callbacks for enhanced training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c095cde3",
   "metadata": {},
   "source": [
    "## 6. Train the Model (Phase 1: Frozen Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c610b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1: Train with frozen base model\n",
    "print(\"Phase 1: Training with frozen base model...\")\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch = train_gen.samples // CONFIG['BATCH_SIZE']\n",
    "validation_steps = val_gen.samples // CONFIG['BATCH_SIZE'] if val_gen else None\n",
    "\n",
    "# Train for initial epochs\n",
    "history_phase1 = model.fit(\n",
    "    train_gen,\n",
    "    epochs=20,  # Initial training phase\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Phase 1 training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8634b72b",
   "metadata": {},
   "source": [
    "## 7. Fine-tuning (Phase 2: Unfreeze Some Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa63235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Fine-tune by unfreezing some layers\n",
    "print(\"Phase 2: Fine-tuning with unfrozen layers...\")\n",
    "\n",
    "# Unfreeze the top layers of the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = len(base_model.layers) // 2\n",
    "\n",
    "# Freeze all layers before fine_tune_at\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Use a lower learning rate for fine-tuning\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=CONFIG['LEARNING_RATE'] / 10),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', 'precision', 'recall']\n",
    ")\n",
    "\n",
    "print(f\"Unfrozen layers: {sum(1 for layer in model.layers if layer.trainable)}\")\n",
    "\n",
    "# Continue training\n",
    "history_phase2 = model.fit(\n",
    "    train_gen,\n",
    "    epochs=CONFIG['EPOCHS'],\n",
    "    initial_epoch=len(history_phase1.history['loss']),\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Fine-tuning completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f5a535",
   "metadata": {},
   "source": [
    "## 8. Enhanced Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5e94b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history1, history2=None):\n",
    "    \"\"\"Plot comprehensive training history\"\"\"\n",
    "    \n",
    "    # Combine histories if we have two phases\n",
    "    if history2:\n",
    "        acc = history1.history['accuracy'] + history2.history['accuracy']\n",
    "        val_acc = history1.history['val_accuracy'] + history2.history['val_accuracy']\n",
    "        loss = history1.history['loss'] + history2.history['loss']\n",
    "        val_loss = history1.history['val_loss'] + history2.history['val_loss']\n",
    "        \n",
    "        # Add vertical line to show where fine-tuning started\n",
    "        fine_tune_epoch = len(history1.history['loss'])\n",
    "    else:\n",
    "        acc = history1.history['accuracy']\n",
    "        val_acc = history1.history['val_accuracy']\n",
    "        loss = history1.history['loss']\n",
    "        val_loss = history1.history['val_loss']\n",
    "        fine_tune_epoch = None\n",
    "    \n",
    "    epochs = range(len(acc))\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(epochs, acc, 'r-', label='Training Accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b-', label='Validation Accuracy')\n",
    "    if fine_tune_epoch:\n",
    "        plt.axvline(x=fine_tune_epoch, color='g', linestyle='--', label='Fine-tuning Start')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs, loss, 'r-', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'b-', label='Validation Loss')\n",
    "    if fine_tune_epoch:\n",
    "        plt.axvline(x=fine_tune_epoch, color='g', linestyle='--', label='Fine-tuning Start')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plot learning rate (if available)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    if 'lr' in history1.history:\n",
    "        lr = history1.history['lr']\n",
    "        if history2 and 'lr' in history2.history:\n",
    "            lr += history2.history['lr']\n",
    "        plt.plot(epochs, lr, 'g-', label='Learning Rate')\n",
    "        plt.title('Learning Rate Schedule')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.yscale('log')\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{CONFIG['MODEL_DIR']}/training_history.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history_phase1, history_phase2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_comprehensive(model, test_generator=None, val_generator=None):\n",
    "    \"\"\"Comprehensive model evaluation with multiple metrics\"\"\"\n",
    "    \n",
    "    # Use test set if available, otherwise validation set\n",
    "    eval_gen = test_generator if test_generator else val_generator\n",
    "    eval_name = \"Test\" if test_generator else \"Validation\"\n",
    "    \n",
    "    if eval_gen is None:\n",
    "        print(\"No evaluation data available!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n=== {eval_name} Set Evaluation ===\")\n",
    "    \n",
    "    # Get predictions\n",
    "    eval_gen.reset()\n",
    "    predictions = model.predict(eval_gen, verbose=1)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Get true labels\n",
    "    true_classes = eval_gen.classes[:len(predicted_classes)]\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    report = classification_report(\n",
    "        true_classes, predicted_classes, \n",
    "        target_names=CONFIG['CLASS_NAMES'],\n",
    "        output_dict=True\n",
    "    )\n",
    "    print(classification_report(true_classes, predicted_classes, target_names=CONFIG['CLASS_NAMES']))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=CONFIG['CLASS_NAMES'], \n",
    "                yticklabels=CONFIG['CLASS_NAMES'])\n",
    "    plt.title(f'{eval_name} Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    \n",
    "    # Plot normalized confusion matrix\n",
    "    plt.subplot(1, 2, 2)\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues',\n",
    "                xticklabels=CONFIG['CLASS_NAMES'], \n",
    "                yticklabels=CONFIG['CLASS_NAMES'])\n",
    "    plt.title(f'{eval_name} Confusion Matrix (Normalized)')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{CONFIG['MODEL_DIR']}/confusion_matrix.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "    print(\"\\nPer-class Accuracy:\")\n",
    "    for i, acc in enumerate(class_accuracy):\n",
    "        print(f\"  {CONFIG['CLASS_NAMES'][i]}: {acc:.3f}\")\n",
    "    \n",
    "    # Overall metrics\n",
    "    overall_accuracy = np.sum(cm.diagonal()) / np.sum(cm)\n",
    "    print(f\"\\nOverall Accuracy: {overall_accuracy:.3f}\")\n",
    "    \n",
    "    return report, cm\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation_report, conf_matrix = evaluate_model_comprehensive(model, test_gen, val_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930b9a43",
   "metadata": {},
   "source": [
    "## 9. Export Models in Multiple Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c02e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model_formats(model, model_dir):\n",
    "    \"\"\"Export model in multiple formats for different use cases\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    print(\"Exporting model in multiple formats...\")\n",
    "    \n",
    "    # 1. Save as H5 (Keras format)\n",
    "    h5_path = f\"{model_dir}/improved_model_{timestamp}.h5\"\n",
    "    model.save(h5_path)\n",
    "    print(f\"✓ H5 model saved: {h5_path}\")\n",
    "    \n",
    "    # 2. Save as SavedModel (TensorFlow format)\n",
    "    savedmodel_path = f\"{model_dir}/saved_model_{timestamp}\"\n",
    "    model.save(savedmodel_path, save_format='tf')\n",
    "    print(f\"✓ SavedModel saved: {savedmodel_path}\")\n",
    "    \n",
    "    # 3. Convert to TFLite (for mobile deployment)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    \n",
    "    # Standard TFLite\n",
    "    tflite_model = converter.convert()\n",
    "    tflite_path = f\"{model_dir}/model_{timestamp}.tflite\"\n",
    "    with open(tflite_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    print(f\"✓ TFLite model saved: {tflite_path}\")\n",
    "    \n",
    "    # Optimized TFLite\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    tflite_optimized = converter.convert()\n",
    "    tflite_opt_path = f\"{model_dir}/optimized_model_{timestamp}.tflite\"\n",
    "    with open(tflite_opt_path, 'wb') as f:\n",
    "        f.write(tflite_optimized)\n",
    "    print(f\"✓ Optimized TFLite model saved: {tflite_opt_path}\")\n",
    "    \n",
    "    # 4. Convert to TensorFlow.js (for web deployment)\n",
    "    try:\n",
    "        import tensorflowjs as tfjs\n",
    "        tfjs_path = f\"{model_dir}/tfjs_{timestamp}\"\n",
    "        tfjs.converters.save_keras_model(model, tfjs_path)\n",
    "        print(f\"✓ TensorFlow.js model saved: {tfjs_path}\")\n",
    "    except ImportError:\n",
    "        print(\"⚠ TensorFlow.js not installed. Run: pip install tensorflowjs\")\n",
    "    \n",
    "    # Save model info\n",
    "    model_info = {\n",
    "        'timestamp': timestamp,\n",
    "        'architecture': 'EfficientNetB0',\n",
    "        'input_shape': (CONFIG['IMG_SIZE'], CONFIG['IMG_SIZE'], 3),\n",
    "        'num_classes': CONFIG['NUM_CLASSES'],\n",
    "        'class_names': CONFIG['CLASS_NAMES'],\n",
    "        'h5_path': h5_path,\n",
    "        'tflite_path': tflite_path,\n",
    "        'optimized_tflite_path': tflite_opt_path\n",
    "    }\n",
    "    \n",
    "    # Save model info as JSON\n",
    "    import json\n",
    "    info_path = f\"{model_dir}/model_info_{timestamp}.json\"\n",
    "    with open(info_path, 'w') as f:\n",
    "        json.dump(model_info, f, indent=2)\n",
    "    print(f\"✓ Model info saved: {info_path}\")\n",
    "    \n",
    "    return model_info\n",
    "\n",
    "# Export the trained model\n",
    "model_info = export_model_formats(model, CONFIG['MODEL_DIR'])\n",
    "print(\"\\nModel export completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337bd029",
   "metadata": {},
   "source": [
    "## 10. Model Integration Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462e7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "=== MODEL INTEGRATION INSTRUCTIONS ===\n",
    "\n",
    "Your trained model has been exported in multiple formats:\n",
    "\n",
    "1. H5 Format (.h5): \n",
    "   - Use for Python/Flask backend\n",
    "   - Copy to your backend/py/ directory\n",
    "   - Load with: tf.keras.models.load_model('model.h5')\n",
    "\n",
    "2. TFLite Format (.tflite):\n",
    "   - Use for mobile apps (Android/iOS)\n",
    "   - Smaller file size, optimized for mobile\n",
    "   - Use TensorFlow Lite interpreter\n",
    "\n",
    "3. TensorFlow.js Format:\n",
    "   - Use for web frontend (React)\n",
    "   - Copy to frontend/public/ directory\n",
    "   - Load with: tf.loadLayersModel()\n",
    "\n",
    "NEXT STEPS:\n",
    "1. Copy the .h5 file to your Flask backend\n",
    "2. Update your Flask server to use the new model\n",
    "3. Test the integration with sample images\n",
    "4. Deploy and monitor performance\n",
    "\n",
    "REMEMBER:\n",
    "- Image preprocessing: resize to 224x224, normalize to [0,1]\n",
    "- Model expects 4D input: (batch_size, 224, 224, 3)\n",
    "- Output: 3 classes [Bacterial, Fungal, Healthy]\n",
    "\"\"\")\n",
    "\n",
    "# Create a simple test script\n",
    "test_script = f'''\n",
    "# Simple test script for the trained model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('{model_info[\"h5_path\"]}')\n",
    "\n",
    "def predict_disease(image_path):\n",
    "    \"\"\"Predict disease from image path\"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = np.array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Make prediction\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions[0])\n",
    "    confidence = predictions[0][predicted_class]\n",
    "    \n",
    "    class_names = {CONFIG['CLASS_NAMES']}\n",
    "    \n",
    "    return {{\n",
    "        'predicted_class': class_names[predicted_class],\n",
    "        'confidence': float(confidence),\n",
    "        'all_predictions': {{\n",
    "            class_names[i]: float(predictions[0][i]) \n",
    "            for i in range(len(class_names))\n",
    "        }}\n",
    "    }}\n",
    "\n",
    "# Example usage:\n",
    "# result = predict_disease('path/to/your/image.jpg')\n",
    "# print(result)\n",
    "'''\n",
    "\n",
    "with open(f\"{CONFIG['MODEL_DIR']}/test_model.py\", 'w') as f:\n",
    "    f.write(test_script)\n",
    "\n",
    "print(f\"Test script created: {CONFIG['MODEL_DIR']}/test_model.py\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
