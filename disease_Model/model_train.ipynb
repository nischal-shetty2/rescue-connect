{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WVd71mJz7atS"
      },
      "source": [
        "## Build the model\n",
        "\n",
        "The next step is to build the model by leveraging transfer learning using Inception V3. By utilizing transfer learning, we can benefit from the pre-trained weights and architecture of Inception V3, which was trained on a large-scale dataset. This approach allows us to take advantage of the learned features and patterns from Inception V3 and apply them to our specific task, maximizing the training accuracy.\n",
        "\n",
        "Given that our dataset is not very large, we will opt for a simpler model architecture. This decision is made with good reason, as using a simpler model helps prevent overfitting and ensures better generalization to unseen data. By striking a balance between model complexity and dataset size, we aim to achieve a robust and accurate model without compromising performance.\n",
        "\n",
        "By employing transfer learning and selecting a suitable model architecture, we set the foundation for building a powerful model that can effectively learn and classify patterns in our specific dataset. This approach saves significant computational resources and training time while still achieving impressive results.\n",
        "\n",
        "You can examine the architecture with `model.summary()` below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooO6Shvao45P",
        "outputId": "0675ec76-dd26-49ec-fbf7-59bb3cce470e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 74, 74, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 74, 74, 32)  96          ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 74, 74, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 72, 72, 32)   9216        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 72, 72, 32)  96          ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 72, 72, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 72, 72, 64)   18432       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 72, 72, 64)  192         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 72, 72, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 35, 35, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 35, 35, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 35, 35, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 35, 35, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 33, 33, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 33, 33, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 33, 33, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 16, 16, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 16, 16, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 16, 16, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 16, 16, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 16, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 16, 16, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 16, 16, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 16, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 16, 16, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 16, 16, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 16, 16, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 16, 16, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 16, 16, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 16, 16, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 16, 16, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 16, 16, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 16, 16, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 16, 16, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 16, 16, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 16, 16, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 16, 16, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 16, 16, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 16, 16, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 16, 16, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 16, 16, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 16, 16, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 16, 16, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 37632)        0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           2408512     ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 3)            195         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11,383,971\n",
            "Trainable params: 2,408,707\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "local_weights_file = \"./src/TransferLearning/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3),\n",
        "                                include_top = False,\n",
        "                                weights = None)\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "last_output = last_layer.output\n",
        "\n",
        "x = tf.keras.layers.Flatten()(last_output)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OskuZ2ThFqmg"
      },
      "outputs": [],
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if logs.get('val_accuracy') >= 0.89:\n",
        "            self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ps7kIRaFRIC"
      },
      "source": [
        "## Prepare the ImageDataGenerator\n",
        "\n",
        "We will prepare the generators for the data. We will set the training set up for data augmentation so it can mimick other poses that the model needs to learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWTisYLQM1aM",
        "outputId": "73fd6979-29b3-44df-bb3e-abc996ae560f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 75 images belonging to 3 classes.\n",
            "Found 30 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "VALIDATION_DIR = \"./src/Validation\"\n",
        "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "TRAINING_DIR = \"./src/Train\"\n",
        "training_datagen = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "\n",
        "train_generator = training_datagen.flow_from_directory(\n",
        "\tTRAINING_DIR,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=5\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "\tVALIDATION_DIR,\n",
        "\ttarget_size=(150,150),\n",
        "\tclass_mode='categorical',\n",
        "  batch_size=5\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Orf1QQlGGyOe"
      },
      "source": [
        "## Train the model and evaluate the results\n",
        "\n",
        "We will train the model for approximately 50-100 epochs, leveraging the use of callbacks. The training process involves iteratively updating the model's weights based on the optimization algorithm and the provided training data. By training the model over multiple epochs, it gradually improves its ability to make accurate predictions.\n",
        "\n",
        "During the training process, we monitor the model's performance on the validation test. The validation test evaluates the model's accuracy on a separate set of data that it has not seen during training. This allows us to assess how well the model generalizes to new, unseen data.\n",
        "\n",
        "Once the model achieves 90% accuracy on the validation test, we will stop the training. This is achieved using a callback mechanism, which triggers a stopping condition when the desired accuracy threshold is reached. Stopping the training at this point ensures that the model has reached a satisfactory level of performance and avoids overfitting, where the model becomes too specialized to the training data and performs poorly on new data.\n",
        "\n",
        "By stopping the training and obtaining the final result of the model, we can assess its overall performance and determine if it meets our desired criteria. This allows us to make informed decisions about the model's readiness for deployment or further improvements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mHX5L7HFXQ7",
        "outputId": "5f058454-a51d-4cc6-c59e-e5db5cf9c004"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "15/15 [==============================] - 6s 205ms/step - loss: 3.7875 - accuracy: 0.4000 - val_loss: 1.0851 - val_accuracy: 0.6667\n",
            "Epoch 2/1000\n",
            "15/15 [==============================] - 3s 232ms/step - loss: 1.1934 - accuracy: 0.5333 - val_loss: 0.6859 - val_accuracy: 0.7333\n",
            "Epoch 3/1000\n",
            "15/15 [==============================] - 2s 147ms/step - loss: 0.8824 - accuracy: 0.6400 - val_loss: 0.6975 - val_accuracy: 0.7333\n",
            "Epoch 4/1000\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.7272 - accuracy: 0.6667 - val_loss: 0.4668 - val_accuracy: 0.8000\n",
            "Epoch 5/1000\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.7805 - accuracy: 0.7333 - val_loss: 0.5284 - val_accuracy: 0.8667\n",
            "Epoch 6/1000\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.5719 - accuracy: 0.8133 - val_loss: 0.5296 - val_accuracy: 0.7667\n",
            "Epoch 7/1000\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.5918 - accuracy: 0.7467 - val_loss: 0.6828 - val_accuracy: 0.7333\n",
            "Epoch 8/1000\n",
            "15/15 [==============================] - 3s 227ms/step - loss: 0.5239 - accuracy: 0.8000 - val_loss: 0.4460 - val_accuracy: 0.7667\n",
            "Epoch 9/1000\n",
            "15/15 [==============================] - 2s 146ms/step - loss: 0.4489 - accuracy: 0.9067 - val_loss: 0.4083 - val_accuracy: 0.8333\n",
            "Epoch 10/1000\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.5356 - accuracy: 0.8267 - val_loss: 0.4529 - val_accuracy: 0.8333\n",
            "Epoch 11/1000\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.4755 - accuracy: 0.8267 - val_loss: 0.5257 - val_accuracy: 0.7667\n",
            "Epoch 12/1000\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.5192 - accuracy: 0.7733 - val_loss: 0.5181 - val_accuracy: 0.8000\n",
            "Epoch 13/1000\n",
            "15/15 [==============================] - 3s 170ms/step - loss: 0.3369 - accuracy: 0.8533 - val_loss: 0.4047 - val_accuracy: 0.8333\n",
            "Epoch 14/1000\n",
            "15/15 [==============================] - 3s 187ms/step - loss: 0.2386 - accuracy: 0.8933 - val_loss: 0.2979 - val_accuracy: 0.8667\n",
            "Epoch 15/1000\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.2433 - accuracy: 0.9200 - val_loss: 0.4856 - val_accuracy: 0.8000\n",
            "Epoch 16/1000\n",
            "15/15 [==============================] - 2s 138ms/step - loss: 0.2323 - accuracy: 0.9200 - val_loss: 0.3082 - val_accuracy: 0.8667\n",
            "Epoch 17/1000\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.3672 - accuracy: 0.8800 - val_loss: 0.3794 - val_accuracy: 0.8333\n",
            "Epoch 18/1000\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 0.2483 - accuracy: 0.9067 - val_loss: 0.5432 - val_accuracy: 0.8000\n",
            "Epoch 19/1000\n",
            "15/15 [==============================] - 3s 184ms/step - loss: 0.1562 - accuracy: 0.9333 - val_loss: 0.2735 - val_accuracy: 0.8667\n",
            "Epoch 20/1000\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.1796 - accuracy: 0.9333 - val_loss: 0.3294 - val_accuracy: 0.8333\n",
            "Epoch 21/1000\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.2443 - accuracy: 0.8933 - val_loss: 0.3991 - val_accuracy: 0.8333\n",
            "Epoch 22/1000\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.1590 - accuracy: 0.9333 - val_loss: 0.3007 - val_accuracy: 0.8333\n",
            "Epoch 23/1000\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.2534 - accuracy: 0.8800 - val_loss: 0.5722 - val_accuracy: 0.8000\n",
            "Epoch 24/1000\n",
            "15/15 [==============================] - 3s 171ms/step - loss: 0.3080 - accuracy: 0.8800 - val_loss: 0.2989 - val_accuracy: 0.8333\n",
            "Epoch 25/1000\n",
            "15/15 [==============================] - 3s 184ms/step - loss: 0.2231 - accuracy: 0.9200 - val_loss: 0.9288 - val_accuracy: 0.7667\n",
            "Epoch 26/1000\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.1697 - accuracy: 0.9333 - val_loss: 0.3805 - val_accuracy: 0.8333\n",
            "Epoch 27/1000\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.2164 - accuracy: 0.8933 - val_loss: 0.6621 - val_accuracy: 0.8000\n",
            "Epoch 28/1000\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.3098 - accuracy: 0.9200 - val_loss: 1.1792 - val_accuracy: 0.7667\n",
            "Epoch 29/1000\n",
            "15/15 [==============================] - 3s 204ms/step - loss: 0.1432 - accuracy: 0.9733 - val_loss: 0.3648 - val_accuracy: 0.8333\n",
            "Epoch 30/1000\n",
            "15/15 [==============================] - 2s 154ms/step - loss: 0.2149 - accuracy: 0.9067 - val_loss: 0.4303 - val_accuracy: 0.8333\n",
            "Epoch 31/1000\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.1737 - accuracy: 0.9333 - val_loss: 0.5632 - val_accuracy: 0.8333\n",
            "Epoch 32/1000\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.1145 - accuracy: 0.9467 - val_loss: 0.4071 - val_accuracy: 0.8333\n",
            "Epoch 33/1000\n",
            "15/15 [==============================] - 2s 127ms/step - loss: 0.1606 - accuracy: 0.9067 - val_loss: 0.5188 - val_accuracy: 0.8333\n",
            "Epoch 34/1000\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.1661 - accuracy: 0.9200 - val_loss: 1.0590 - val_accuracy: 0.7667\n",
            "Epoch 35/1000\n",
            "15/15 [==============================] - 3s 234ms/step - loss: 0.2393 - accuracy: 0.9067 - val_loss: 0.3889 - val_accuracy: 0.8667\n",
            "Epoch 36/1000\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0685 - accuracy: 0.9867 - val_loss: 0.4272 - val_accuracy: 0.8000\n",
            "Epoch 37/1000\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.2166 - accuracy: 0.9200 - val_loss: 0.6261 - val_accuracy: 0.8000\n",
            "Epoch 38/1000\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.1259 - accuracy: 0.9600 - val_loss: 0.5394 - val_accuracy: 0.8333\n",
            "Epoch 39/1000\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.2269 - accuracy: 0.9333 - val_loss: 0.7755 - val_accuracy: 0.7667\n",
            "Epoch 40/1000\n",
            "15/15 [==============================] - 3s 198ms/step - loss: 0.0695 - accuracy: 0.9733 - val_loss: 0.7011 - val_accuracy: 0.7667\n",
            "Epoch 41/1000\n",
            "15/15 [==============================] - 2s 156ms/step - loss: 0.1563 - accuracy: 0.9600 - val_loss: 0.4183 - val_accuracy: 0.8333\n",
            "Epoch 42/1000\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.2064 - accuracy: 0.8933 - val_loss: 1.0250 - val_accuracy: 0.7667\n",
            "Epoch 43/1000\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.1546 - accuracy: 0.9467 - val_loss: 0.5087 - val_accuracy: 0.8667\n",
            "Epoch 44/1000\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 0.0378 - accuracy: 0.9867 - val_loss: 0.3716 - val_accuracy: 0.8333\n",
            "Epoch 45/1000\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.0615 - accuracy: 0.9733 - val_loss: 0.5877 - val_accuracy: 0.8000\n",
            "Epoch 46/1000\n",
            "15/15 [==============================] - 3s 197ms/step - loss: 0.0325 - accuracy: 0.9867 - val_loss: 0.3679 - val_accuracy: 0.8667\n",
            "Epoch 47/1000\n",
            "15/15 [==============================] - 2s 145ms/step - loss: 0.1809 - accuracy: 0.9467 - val_loss: 0.5657 - val_accuracy: 0.8333\n",
            "Epoch 48/1000\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0799 - accuracy: 0.9867 - val_loss: 0.3316 - val_accuracy: 0.8667\n",
            "Epoch 49/1000\n",
            "15/15 [==============================] - 2s 127ms/step - loss: 0.0717 - accuracy: 0.9600 - val_loss: 0.3377 - val_accuracy: 0.8667\n",
            "Epoch 50/1000\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.1243 - accuracy: 0.9467 - val_loss: 0.4329 - val_accuracy: 0.8333\n",
            "Epoch 51/1000\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.0998 - accuracy: 0.9867 - val_loss: 0.3353 - val_accuracy: 0.8667\n",
            "Epoch 52/1000\n",
            "15/15 [==============================] - 3s 194ms/step - loss: 0.1336 - accuracy: 0.9467 - val_loss: 0.3654 - val_accuracy: 0.8667\n",
            "Epoch 53/1000\n",
            "15/15 [==============================] - 2s 160ms/step - loss: 0.0640 - accuracy: 0.9733 - val_loss: 0.6688 - val_accuracy: 0.8000\n",
            "Epoch 54/1000\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.1426 - accuracy: 0.9600 - val_loss: 0.6799 - val_accuracy: 0.8000\n",
            "Epoch 55/1000\n",
            "15/15 [==============================] - 2s 129ms/step - loss: 0.0479 - accuracy: 0.9867 - val_loss: 0.6291 - val_accuracy: 0.8667\n",
            "Epoch 56/1000\n",
            "15/15 [==============================] - 2s 136ms/step - loss: 0.1724 - accuracy: 0.9333 - val_loss: 0.5807 - val_accuracy: 0.7667\n",
            "Epoch 57/1000\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0502 - accuracy: 0.9733 - val_loss: 0.5576 - val_accuracy: 0.7667\n",
            "Epoch 58/1000\n",
            "15/15 [==============================] - 2s 171ms/step - loss: 0.0945 - accuracy: 0.9867 - val_loss: 0.4742 - val_accuracy: 0.8000\n",
            "Epoch 59/1000\n",
            "15/15 [==============================] - 3s 186ms/step - loss: 0.1144 - accuracy: 0.9867 - val_loss: 0.5446 - val_accuracy: 0.8667\n",
            "Epoch 60/1000\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.0973 - accuracy: 0.9600 - val_loss: 0.5524 - val_accuracy: 0.8000\n",
            "Epoch 61/1000\n",
            "15/15 [==============================] - 2s 135ms/step - loss: 0.1675 - accuracy: 0.9333 - val_loss: 0.6264 - val_accuracy: 0.8000\n",
            "Epoch 62/1000\n",
            "15/15 [==============================] - 2s 137ms/step - loss: 0.1159 - accuracy: 0.9600 - val_loss: 0.9488 - val_accuracy: 0.8000\n",
            "Epoch 63/1000\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.1258 - accuracy: 0.9333 - val_loss: 0.4348 - val_accuracy: 0.8333\n",
            "Epoch 64/1000\n",
            "15/15 [==============================] - 3s 234ms/step - loss: 0.0526 - accuracy: 0.9733 - val_loss: 0.5581 - val_accuracy: 0.8000\n",
            "Epoch 65/1000\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0460 - accuracy: 0.9867 - val_loss: 1.2026 - val_accuracy: 0.8000\n",
            "Epoch 66/1000\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 0.1198 - accuracy: 0.9600 - val_loss: 0.6502 - val_accuracy: 0.8333\n",
            "Epoch 67/1000\n",
            "15/15 [==============================] - 2s 133ms/step - loss: 0.0253 - accuracy: 0.9867 - val_loss: 0.6100 - val_accuracy: 0.8333\n",
            "Epoch 68/1000\n",
            "15/15 [==============================] - 2s 146ms/step - loss: 0.0970 - accuracy: 0.9733 - val_loss: 0.9967 - val_accuracy: 0.8000\n",
            "Epoch 69/1000\n",
            "15/15 [==============================] - 3s 194ms/step - loss: 0.0806 - accuracy: 0.9733 - val_loss: 0.6293 - val_accuracy: 0.8333\n",
            "Epoch 70/1000\n",
            "15/15 [==============================] - 2s 130ms/step - loss: 0.0753 - accuracy: 0.9867 - val_loss: 0.5507 - val_accuracy: 0.8333\n",
            "Epoch 71/1000\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 0.0972 - accuracy: 0.9733 - val_loss: 0.7831 - val_accuracy: 0.8333\n",
            "Epoch 72/1000\n",
            "15/15 [==============================] - 2s 148ms/step - loss: 0.1053 - accuracy: 0.9600 - val_loss: 0.5924 - val_accuracy: 0.8333\n",
            "Epoch 73/1000\n",
            "15/15 [==============================] - 3s 206ms/step - loss: 0.1012 - accuracy: 0.9600 - val_loss: 0.9668 - val_accuracy: 0.8000\n",
            "Epoch 74/1000\n",
            "15/15 [==============================] - 2s 134ms/step - loss: 0.0910 - accuracy: 0.9600 - val_loss: 0.4640 - val_accuracy: 0.8667\n",
            "Epoch 75/1000\n",
            "15/15 [==============================] - 2s 131ms/step - loss: 0.1461 - accuracy: 0.9600 - val_loss: 0.3369 - val_accuracy: 0.9000\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator, epochs=1000, steps_per_epoch=15, validation_data = validation_generator, validation_steps=6, callbacks=[callbacks])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "aeTRVCr6aosw",
        "outputId": "91317301-706e-484b-96a9-5803e53082c2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the results\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JHRufhQYJJLU"
      },
      "source": [
        "## Export Model\n",
        "After testing the model and confirming its accuracy for the Minimum Viable Product (MVP), the next step is to export the model in both h5 and TFLite formats.\n",
        "\n",
        "Exporting the model allows us to save its architecture, weights, and other necessary parameters in a file format that can be easily loaded and utilized for future predictions or deployment. The h5 format is a standard file format in the Keras library, which can be used to store the entire model configuration and weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "9OxA4uZRju_5",
        "outputId": "85ee1adb-0e74-4914-a140-b2a80685dd4f"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Save the model in h5 format\n",
        "\n",
        "model.save('./model/model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "361O7x0eKomh",
        "outputId": "cec82d43-6d0d-4648-97be-43537c66ee9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 71). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmp9w6xfge9\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmp9w6xfge9\\assets\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "loaded_model = model\n",
        "\n",
        "# Convert the model to TFLite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "# Save the TFLite model to a file\n",
        "with open('./model/optimized_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflowjs as tfjs\n",
        "\n",
        "#Save the model in TensorflowJS format\n",
        "\n",
        "tfjs.converters.save_keras_model(model, './model/tfjs')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EEnm-jdXlpq6"
      },
      "source": [
        "## Load Model\n",
        "\n",
        "Once we have saved a trained model in the h5 file format, we can easily import it without the necessity of retraining the model from scratch. This means we can directly utilize the saved model to make predictions on new data, saving time and computational resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5RK__8wYlsav"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "model = tf.keras.models.load_model('./model/model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHmyf1rVKUOg",
        "outputId": "5ff4f3b0-b438-4e9a-910a-2f4eb8531f21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
